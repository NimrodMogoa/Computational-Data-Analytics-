{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link href=\"style.css\" rel=\"stylesheet\"></link> \n",
    "<a name=\"TOC\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:2.8em;font-weight:bold\">Regular Expressions</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Expressions are a special form of text string that is used to match patterns withing another string. They are widely used in text search, input verification, text splitting and replacing parts of a text.\n",
    "Regular Expressions are implemented in most modern programming languages.\n",
    "\n",
    "Unfortunately there are some differences (called flavors) in the implementation of Regular Expressions across programming languages. These are mainly minor differences in character breakouts and syntax. This document uses the Python flavor. I will highlight where other flavors differ without going into details on these differences.\n",
    "\n",
    "In addition to using Regular Expressions in programming many text editors offer the use of Regular Expressions in the Search and Replace operation to quickly make changes across many large files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given the task to improve the security of your companies computers. The aim is to use machine learning to predict fraudulent activities in order to be able to stop them early in future.\n",
    "\n",
    "As training data you are given the activity log files of your companies computers for the past year. There are 10 computers which each produce one log file per day. This is an application log witch shows the internal computers processes.\n",
    "The log files are text files looking like the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following shows the first 50 lines of the log file. The total file size is about 300 lines per day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555687137\t19 April 2019 at 08:18:57 GMT-7: Info: Sending burger event 13.0.6, (null)\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555689568\t19 April 2019 at 08:59:28 GMT-7: Info: network exchange succeeded\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555689568\t19 April 2019 at 08:59:28 GMT-7: Info: vaar exchange succeeded\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555689569\t19 April 2019 at 08:59:29 GMT-7: Info: Sending burger event 51.1.2, (null)\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555689569\t19 April 2019 at 08:59:29 GMT-7: Info: IPsec connectivity probe: context: periodic correlationId: 6FAA6C11-E769-4857-8025-E2D467F8D3DC-991; identifier: openvpn_27817_tcp; succeeded: true; duration: 392; pingPacketLoss: 0.0; stages: [[succeeded: true; protocol: .tcp; port: 27817; duration: 392; exchanges[0] { requestPackets: 1; sent packets: 1; received packets: 1; responsePackets: 1;} exchanges[1] { requestPackets: 2; sent packets: 2; received packets: 3; responsePackets: 3;} exchanges[2] { requestPackets: 4; sent packets: 4; received packets: 2; responsePackets: 2;}]]\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555689569\t19 April 2019 at 08:59:29 GMT-7: Info: Sending burger event 51.1.2, (null)\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555689569\t19 April 2019 at 08:59:29 GMT-7: Info: IPsec connectivity probe: context: periodic correlationId: 6FAA6C11-E769-4857-8025-E2D467F8D3DC-991; identifier: openvpn_27817_udp; succeeded: true; duration: 114; pingPacketLoss: 0.0; stages: [[succeeded: true; protocol: .udp; port: 27817; duration: 114; exchanges[0] { requestPackets: 1; sent packets: 1; received packets: 1; responsePackets: 1;} exchanges[1] { requestPackets: 2; sent packets: 2; received packets: 4; responsePackets: 4;} exchanges[2] { requestPackets: 6; sent packets: 6; received packets: 3; responsePackets: 3;}]]\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555700373\t19 April 2019 at 11:59:33 GMT-7: Info: network exchange succeeded\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555700373\t19 April 2019 at 11:59:33 GMT-7: Info: vaar exchange succeeded\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555700374\t19 April 2019 at 11:59:34 GMT-7: Info: Sending burger event 51.1.2, (null)\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555700374\t19 April 2019 at 11:59:34 GMT-7: Info: IPsec connectivity probe: context: periodic correlationId: 6FAA6C11-E769-4857-8025-E2D467F8D3DC-992; identifier: openvpn_27817_tcp; succeeded: true; duration: 355; pingPacketLoss: 0.0; stages: [[succeeded: true; protocol: .tcp; port: 27817; duration: 355; exchanges[0] { requestPackets: 1; sent packets: 1; received packets: 1; responsePackets: 1;} exchanges[1] { requestPackets: 2; sent packets: 2; received packets: 3; responsePackets: 3;} exchanges[2] { requestPackets: 4; sent packets: 4; received packets: 2; responsePackets: 2;}]]\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555700374\t19 April 2019 at 11:59:34 GMT-7: Info: Sending burger event 51.1.2, (null)\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555700374\t19 April 2019 at 11:59:34 GMT-7: Info: IPsec connectivity probe: context: periodic correlationId: 6FAA6C11-E769-4857-8025-E2D467F8D3DC-992; identifier: openvpn_27817_udp; succeeded: true; duration: 144; pingPacketLoss: 0.0; stages: [[succeeded: true; protocol: .udp; port: 27817; duration: 144; exchanges[0] { requestPackets: 1; sent packets: 1; received packets: 1; responsePackets: 1;} exchanges[1] { requestPackets: 2; sent packets: 2; received packets: 4; responsePackets: 4;} exchanges[2] { requestPackets: 6; sent packets: 6; received packets: 3; responsePackets: 3;}]]\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: === Starting ===\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Pinging service\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Adding 1 service task\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Sending 1 service task\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Adding 129 service task\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Sending 129 service task\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Processing 1 service task response\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Service ping succeeded\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Processed 1 service task response\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Processing 129 service task response\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Processed 129 service task response\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Adding 21 service task\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Sending 21 service task\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Adding 24 service task\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Sending 24 service task\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Processing 21 service task response\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Licensing service initialization: License found\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Licensing service initilized\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Processed 21 service task response\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Processing 24 service task response\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Licensing service initialization: Found 1 ticket(s)\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Processed 24 service task response\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Adding 253 service task\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Sending 253 service task\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Running version 4.6.1(605)\n",
    "HMA! Pro VPN\t1555705477\t19 April 2019 at 13:24:37 GMT-7: === Starting ===\n",
    "HMA! Pro VPN\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Arguments: backgroundMode\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Processing 253 service task response\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705477\t19 April 2019 at 13:24:37 GMT-7: Info: Network connection state changed from notInitialized to invalid\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705478\t19 April 2019 at 13:24:38 GMT-7: Info: Processed 253 service task response\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705479\t19 April 2019 at 13:24:39 GMT-7: XPC connection resumed [790]\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705479\t19 April 2019 at 13:24:39 GMT-7: Info: Connection rules - networks changed: ''\n",
    "96HLSU34RN.com.privax.osx.provpn.helper\t1555705479\t19 April 2019 at 13:24:39 GMT-7: Info: Connection rules - networks changed: '38!ISC'\n",
    "\n",
    "~~~\n",
    "\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to analyze the information contained in these files it needs to be extracted and parsed into something like a Pandas Dataframe. As the files are not in a format that can be directly imported into a Dataframe the options are:\n",
    "* Manually extracting the information. Due to the volume not feasible\n",
    "* Writing a Python function that filters the information contained. This can get very complex, hard to read and modify later and the processing will likely be slow\n",
    "* Using Regular Expressions to extract the information contained into a set of lists\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following Regular Expression could be used to extract the Information from the Application Log you don't need to fully understand the Expression at this point it serves as an example and will become clear later:\n",
    "\n",
    "~~~\n",
    "^                               # Only Match at the beginning of a line\n",
    "(?P<Source>.+\\w)                # Any Character sequence ending on a word character stored as group \"Source\"\n",
    "\\s+                             # 1..n whitespace Characters\n",
    "(?P<Thread>\\d{10})              # 10 digits\n",
    "\\s+                             # 1..n whitespace Characters\n",
    "(?P<Day>\\d{1,2})                # One or two digits stored in group \"Day\"\n",
    "\\s                              # 1 whitespace Character\n",
    "(?P<Month>\\w{3,})               # Three or more Characters stored in group \"Month\"\n",
    "\\s                              # 1 whitespace Character\n",
    "(?P<Year>\\d{4})                 # Four digits stored in group \"Year\"\n",
    "\\s+at\\s+                        # 1..n whitespace Characters followed by the word \"at\" followed by 1..n whitespace Characters\n",
    "(?P<Time>\\d{1,2}:\\d{1,2}:\\d{2}) # 1 or 2 digits followed by : followed by 1 or 2 digits followed by : followed by 2 digits stored in group \"Time\"\n",
    "\\s                              # 1 whitespace Character\n",
    "(?P<Timezone>\\w{3}[-+]\\d{1,2})  # 3 Characters followed by + or - followed by 1 or 2 digits stored in group \"Timezone\"\n",
    ":\\s                             # : followed by 1 whitespace Character\n",
    "(?P<Event>.+)                   # The rest of the line stored in group \"Event\"\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the solution in Python you can use the following code. The file 'application1.log' contains the sample data.\n",
    "The best way to read the file is a Pandas Series (one row per line of the text file) which can be done by using the read_csv method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T03:09:36.283134Z",
     "start_time": "2019-04-26T03:09:35.556228Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "datapath = Path('data')\n",
    "\n",
    "Log_S = pd.read_csv(datapath/Path('application1.log'),\n",
    "                    delimiter = \"\\n\",     # The delimiter is set to \"\\n\" which is a regular expression for newline\n",
    "                    squeeze = True,       # squezze = True results in a Series object instead of a Dataframe\n",
    "                    header = None)        # The textfile has no header information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next use a Regular Expression to extract the information from each line using the str.extract method. The Regular Expression as well as the method will be explained in more detail later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T03:09:36.768395Z",
     "start_time": "2019-04-26T03:09:36.760778Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "regex = r\"\"\"\n",
    "^                               # Only Match at the beginning of a line\n",
    "(?P<Source>.+\\w)                # Any Character sequence ending on a word character stored as group \"Source\"\n",
    "\\s+                             # 1..n whitespace Characters\n",
    "(?P<Thread>\\d{10})              # 10 digits\n",
    "\\s+                             # 1..n whitespace Characters\n",
    "(?P<Day>\\d{1,2})                # One or two digits stored in group \"Day\"\n",
    "\\s                              # 1 whitespace Character\n",
    "(?P<Month>\\w{3,})               # Three or more Characters stored in group \"Month\"\n",
    "\\s                              # 1 whitespace Character\n",
    "(?P<Year>\\d{4})                 # Four digits stored in group \"Year\"\n",
    "\\s+at\\s+                        # 1..n whitespace Characters followed by the word \"at\" followed by 1..n whitespace Characters\n",
    "(?P<Time>\\d{1,2}:\\d{1,2}:\\d{2}) # 1 or 2 digits followed by : followed by 1 or 2 digits followed by : followed by 2 digits stored in group \"Time\"\n",
    "\\s                              # 1 whitespace Character\n",
    "(?P<Timezone>\\w{3}[-+]\\d{1,2})  # 3 Characters followed by + or - followed by 1 or 2 digits stored in group \"Timezone\"\n",
    ":\\s                             # : followed by 1 whitespace Character\n",
    "(?P<Event>.+)                   # The rest of the line stored in group \"Event\"\n",
    "\"\"\"\n",
    "\n",
    "# Pandas.Series.str.extract uses a regular expression and extracts all matched groups into a DataFrame\n",
    "Log_df = Log_S.str.extract(regex,                     # the Regular Expression String\n",
    "                           re.MULTILINE | re.VERBOSE) # flags for the evaluation of the Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T03:09:43.695636Z",
     "start_time": "2019-04-26T03:09:43.668165Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Thread</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Time</th>\n",
       "      <th>Timezone</th>\n",
       "      <th>Event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96HLSU34RN.com.privax.osx.provpn.helper</td>\n",
       "      <td>1555687137</td>\n",
       "      <td>19</td>\n",
       "      <td>April</td>\n",
       "      <td>2019</td>\n",
       "      <td>08:18:57</td>\n",
       "      <td>GMT-7</td>\n",
       "      <td>Info: Sending burger event 13.0.6, (null)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96HLSU34RN.com.privax.osx.provpn.helper</td>\n",
       "      <td>1555689568</td>\n",
       "      <td>19</td>\n",
       "      <td>April</td>\n",
       "      <td>2019</td>\n",
       "      <td>08:59:28</td>\n",
       "      <td>GMT-7</td>\n",
       "      <td>Info: network exchange succeeded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96HLSU34RN.com.privax.osx.provpn.helper</td>\n",
       "      <td>1555689568</td>\n",
       "      <td>19</td>\n",
       "      <td>April</td>\n",
       "      <td>2019</td>\n",
       "      <td>08:59:28</td>\n",
       "      <td>GMT-7</td>\n",
       "      <td>Info: vaar exchange succeeded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96HLSU34RN.com.privax.osx.provpn.helper</td>\n",
       "      <td>1555689569</td>\n",
       "      <td>19</td>\n",
       "      <td>April</td>\n",
       "      <td>2019</td>\n",
       "      <td>08:59:29</td>\n",
       "      <td>GMT-7</td>\n",
       "      <td>Info: Sending burger event 51.1.2, (null)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96HLSU34RN.com.privax.osx.provpn.helper</td>\n",
       "      <td>1555689569</td>\n",
       "      <td>19</td>\n",
       "      <td>April</td>\n",
       "      <td>2019</td>\n",
       "      <td>08:59:29</td>\n",
       "      <td>GMT-7</td>\n",
       "      <td>Info: IPsec connectivity probe: context: perio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Source      Thread Day  Month  Year  \\\n",
       "0  96HLSU34RN.com.privax.osx.provpn.helper  1555687137  19  April  2019   \n",
       "1  96HLSU34RN.com.privax.osx.provpn.helper  1555689568  19  April  2019   \n",
       "2  96HLSU34RN.com.privax.osx.provpn.helper  1555689568  19  April  2019   \n",
       "3  96HLSU34RN.com.privax.osx.provpn.helper  1555689569  19  April  2019   \n",
       "4  96HLSU34RN.com.privax.osx.provpn.helper  1555689569  19  April  2019   \n",
       "\n",
       "       Time Timezone                                              Event  \n",
       "0  08:18:57    GMT-7          Info: Sending burger event 13.0.6, (null)  \n",
       "1  08:59:28    GMT-7                   Info: network exchange succeeded  \n",
       "2  08:59:28    GMT-7                      Info: vaar exchange succeeded  \n",
       "3  08:59:29    GMT-7          Info: Sending burger event 51.1.2, (null)  \n",
       "4  08:59:29    GMT-7  Info: IPsec connectivity probe: context: perio...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Log_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen here the extraction resulted in a Dataframe that can be used for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T17:12:36.612124Z",
     "start_time": "2019-04-25T17:12:35.378394Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T17:12:39.906226Z",
     "start_time": "2019-04-25T17:12:39.818837Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "sensortext <- readLines('application1.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T17:20:36.130456Z",
     "start_time": "2019-04-25T17:20:35.916230Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpy2.robjects.packages.Package as a <module 'rematch2'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "importr(\"stringr\")\n",
    "importr(\"rematch2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T17:24:14.261014Z",
     "start_time": "2019-04-25T17:24:14.121247Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[90m# A tibble: 6 x 10\u001b[39m\n",
       "  Source  Thread  Day    Month  Year  Time  Timezone Event .text         .match\n",
       "  \u001b[3m\u001b[90m<list>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<list>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<list>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<list>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<lis>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<lis>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<list>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<lis>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<list>\u001b[39m\u001b[23m\n",
       "\u001b[90m1\u001b[39m \u001b[90m<chr [\u001b[0m… \u001b[90m<chr [\u001b[0m… \u001b[90m<chr \u001b[0m… \u001b[90m<chr \u001b[0m… \u001b[90m<chr\u001b[0m… \u001b[90m<chr\u001b[0m… \u001b[90m<chr [1\u001b[0m… \u001b[90m<chr\u001b[0m… \u001b[90m\"\u001b[39m96HLSU34RN.… \u001b[90m<chr \u001b[0m…\n",
       "\u001b[90m2\u001b[39m \u001b[90m<chr [\u001b[0m… \u001b[90m<chr [\u001b[0m… \u001b[90m<chr \u001b[0m… \u001b[90m<chr \u001b[0m… \u001b[90m<chr\u001b[0m… \u001b[90m<chr\u001b[0m… \u001b[90m<chr [1\u001b[0m… \u001b[90m<chr\u001b[0m… \u001b[90m\"\u001b[39m96HLSU34RN.… \u001b[90m<chr \u001b[0m…\n",
       "\u001b[90m3\u001b[39m \u001b[90m<chr [\u001b[0m… \u001b[90m<chr [\u001b[0m… \u001b[90m<chr \u001b[0m… \u001b[90m<chr \u001b[0m… \u001b[90m<chr\u001b[0m… \u001b[90m<chr\u001b[0m… \u001b[90m<chr [1\u001b[0m… \u001b[90m<chr\u001b[0m… \u001b[90m\"\u001b[39m96HLSU34RN.… \u001b[90m<chr \u001b[0m…\n",
       "\u001b[90m4\u001b[39m \u001b[90m<chr [\u001b[0m… \u001b[90m<chr [\u001b[0m… \u001b[90m<chr \u001b[0m… \u001b[90m<chr \u001b[0m… \u001b[90m<chr\u001b[0m… \u001b[90m<chr\u001b[0m… \u001b[90m<chr [1\u001b[0m… \u001b[90m<chr\u001b[0m… \u001b[90m\"\u001b[39m96HLSU34RN.… \u001b[90m<chr \u001b[0m…\n",
       "\u001b[90m5\u001b[39m \u001b[90m<chr [\u001b[0m… \u001b[90m<chr [\u001b[0m… \u001b[90m<chr \u001b[0m… \u001b[90m<chr \u001b[0m… \u001b[90m<chr\u001b[0m… \u001b[90m<chr\u001b[0m… \u001b[90m<chr [1\u001b[0m… \u001b[90m<chr\u001b[0m… \u001b[90m\"\u001b[39m96HLSU34RN.… \u001b[90m<chr \u001b[0m…\n",
       "\u001b[90m6\u001b[39m \u001b[90m<chr [\u001b[0m… \u001b[90m<chr [\u001b[0m… \u001b[90m<chr \u001b[0m… \u001b[90m<chr \u001b[0m… \u001b[90m<chr\u001b[0m… \u001b[90m<chr\u001b[0m… \u001b[90m<chr [1\u001b[0m… \u001b[90m<chr\u001b[0m… \u001b[90m\"\u001b[39m96HLSU34RN.… \u001b[90m<chr \u001b[0m…\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "regex <- paste(\"^\",                                 # Only Match at the beginning of a line\n",
    "               \"(?<Source>.+\\\\w)\",                  # Any Character sequence ending on a word character stored as group \"Source\"\n",
    "               \"\\\\s+\",                              # 1..n whitespace Characters\n",
    "               \"(?<Thread>\\\\d{10})\",                # 10 digits\n",
    "               \"\\\\s+\",                              # 1..n whitespace Characters\n",
    "               \"(?<Day>\\\\d{1,2})\",                  # One or two digits stored in group \"Day\"\n",
    "               \"\\\\s\",                               # 1 whitespace Character\n",
    "               \"(?<Month>\\\\w{3,})\",                 # Three or more Characters stored in group \"Month\"\n",
    "               \"\\\\s\",                               # 1 whitespace Character\n",
    "               \"(?<Year>\\\\d{4})\",                   # Four digits stored in group \"Year\"\n",
    "               \"\\\\s+at\\\\s+\",                        # 1..n whitespace Characters followed by the word \"at\" followed by 1..n whitespace Characters\n",
    "               \"(?<Time>\\\\d{1,2}:\\\\d{1,2}:\\\\d{2})\", # 1 or 2 digits followed by : followed by 1 or 2 digits followed by : followed by 2 digits stored in group \"Time\"\n",
    "               \"\\\\s\",                               # 1 whitespace Character\n",
    "               \"(?<Event>.+)\"                       # The rest of the line stored in group \"Event\"\"\n",
    "               , sep=\"\")\n",
    "\n",
    "match_as_nested_list = str_match_all(sensortext,\n",
    "                                     regex)\n",
    "match_as_tidy_df = re_match_all(sensortext,\n",
    "                                regex,\n",
    "                                perl = TRUE)\n",
    "head(match_as_tidy_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Regular Expression testers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Regular Expressions can be complex and look daunting to develop. The easiest way to develop them is using a Regular Expression tester program. There are many different options for this including web based ones and programs that run locally on the computer.\n",
    "\n",
    "One of the best options is  https://regex101.com which allows to switch between different Regular Expression flavors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"regex101.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Adjust the flavor to Python for Python and PCRE for usage with R.\n",
    "<img src=\"regex101_flavor.png\" width=\"160\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Copy and paste at least a part of the text you want to match into the Test String box.\n",
    "<img src=\"regex101_testString.png\" width=\"480\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Develop your Regular Expression in this box. Matches will directly be highlighted in the Test String box and also shown in the Match box.\n",
    "<img src=\"regex101_expression.png\" width=\"480\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Matches and match groups are shown here:\n",
    "<img src=\"regex101_match.png\" width=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described a Regular Expression matches patterns in text. This is done from left to right - just like a human would read the text. It is important to keep in mind that the Regular Expression always **matches the first occurrence** of the pattern in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literal Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-29T15:50:29.757Z"
    }
   },
   "source": [
    "The most basic form of a match is a literal match. The Expression\n",
    "~~~\n",
    "Regular\n",
    "~~~\n",
    "matches the word \"Regular\".\n",
    "\n",
    "If you match the Expression\n",
    "~~~\n",
    "A\n",
    "~~~\n",
    "with the string\n",
    "~~~\n",
    "MBAN Allstars\n",
    "~~~\n",
    "it will match the `A` in `MBAN` and than be done.\n",
    "\n",
    "Keep in mind that by standard Regular Expressions are **Case Sensitive**. This can be switched of in the Regular Expression options.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of Characters with a special meaning within Regular Expressions. These are called **metacharacters**. They are:\n",
    "* `[`\n",
    "* `\\`\n",
    "* `^`\n",
    "* `$`\n",
    "* `.`\n",
    "* `|`\n",
    "* `?`\n",
    "* `*`\n",
    "* `+`\n",
    "* `(`\n",
    "* `)`\n",
    "\n",
    "In order to match any of these in a piece of text they need to be escaped by preceding them a `\\`.\n",
    "\n",
    "In order to match the string `pi+3` in a text the Regular Expression would be:\n",
    "~~~\n",
    "pi\\+3\n",
    "~~~\n",
    "\n",
    "It is important that if the backslash is omitted the Regular Expression `pi+3` is still valid, but matches a string starting with a `p` followed by a number of `i`s and a `3` - for example `piiiii3` or `pi3` would both be matched.\n",
    "\n",
    "Depending on the programming language you use Regular Expressions with you might need to use additional escapes. How to handle this for Python and R will be explained later on.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non printable Characters, ASCII and Unicode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Expressions can also match non printable characters. The most commonly used are:\n",
    "\n",
    "|Character|Regular Expression|ASCII|Comment|\n",
    "|--------:|:----------------:|:---:|:------|\n",
    "|Tab|`\\t`|`0x09`| |\n",
    "|Carriage Return|`\\r`|`0x0D`|Windows text files use `\\r\\n` for the end of a line while UNIX (Mac) text files use only `\\n`|\n",
    "|Line Feed|`\\n`|`0x0A`| |\n",
    "\n",
    "Any other character can be included in a Regular Expression using either the ASCII code:\n",
    "~~~\n",
    "\\xA9\n",
    "~~~\n",
    "stands for the Copyright ® symbol with is `A9` in the ASCII table. It is important to note that the `x` after the backslash has to be lowercase and any letters from the ASCII symbol have to be uppercase (like the `A` in `A9`).\n",
    "\n",
    "To include Unicode characters works similarly:\n",
    "~~~\n",
    "\\u20AC\n",
    "~~~\n",
    "matches the € symbol.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Expressions allow to match a choice of symbols. Let's say you want to match both the words `Hello` and the German word `Hallo`. The difference is only one letter. To match both word the Regular Expression would look like:\n",
    "~~~\n",
    "H[ae]llo\n",
    "~~~\n",
    "This matches a `H` followed by either of the letters `a` or `e` followed by the letters `llo`. It doesn't match the word `Haello`.\n",
    "\n",
    "In general to match a group of characters put them in square brackets. You can include as many characters as desired in the brackets and even use ranges.\n",
    "The Expression `[abcdef_]` matches any one of the characters from `a` to `f` and the underscore character. A shorter way for the same would be `[a-f_]`.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean Or"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to match either of two characters, sets or groups (these will be explained later) use the or `|` operator.\n",
    "\n",
    "In the example used above the expression `[ae]` could have also been written as `a|e`.\n",
    "\n",
    "The or operator doesn't work on single characters. The expression `MBA|MIB` matches either word and does not match `MBAIB` or `MBMIB`.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also negate a character set by using the `^` symbol at the beginning of the character set.\n",
    "~~~\n",
    "MBA[^N]\n",
    "~~~\n",
    "Matches the letters `MBA` followed by something that is not the character `N`. This means it will not match `MBAN`, but also not match `MBA` either as there must be a fourth character that is not a `N` in the string to match. It would for example match the string `MBAs`.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escaped Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside a character set the [special characters](#Special-Characters) that normally do need to be escaped to be matched do not apply. The only characters that need to be escaped in a character set are its closing bracket `]` and the backslash `\\`. For example to match both the strings `4+5` and `4*5` the Regular Expression would be `4[*+]5`.\n",
    "\n",
    "I case you want to match the caret `^` symbol within a character set don't place it in the first position.\n",
    "The expression `[^x]` will match any character except the `x`, but `[x^]` will match either the character `x` or the `^`.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abbreviated Character Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are many commonly used character sets there are abbreviated forms for them.\n",
    "\n",
    "| Abbreviation | Matches          | Description |\n",
    "|--------------|------------------|:-------------|\n",
    "| `\\d`         | `[0-9]`          | Digit                    |\n",
    "| `\\D`         | `[^0-9]`         | non-digits               |\n",
    "| `\\s`         | `[ \\t\\r\\n\\v\\f]`  | any whitespace character (tab, line feed, form feed, carriage return and space) <br> plus some other Unicode ones |\n",
    "| `\\S`         | `[^ \\t\\r\\n\\v\\f]` | anything but a whitespace character |\n",
    "| `\\w`         | `[A-Za-z0-9_]`   | Alphanumeric characters plus _ |\n",
    "| `\\W`         | `[^A-Za-z0-9_]`  | Non Alphanumeric characters |\n",
    "| `.`          | `[^\\n]`          | The dot matches anything except the newline character. It is a wildcard and as such<br>powerful but dangerous. It is the most misused Regular Expression shorthand and<br>should be omitted whenever possible.|\n",
    "\n",
    "Note that the **uppercase** version of these is always the **negation** of the lowercase set.\n",
    "\n",
    "When using the negated forms inside square brackets `[]` be careful. The expression `[^\\d\\s]` is not equivalent to `[\\D\\S]`! <br>\n",
    "The first one `[^\\d\\s]` evaluates to `[^0-9 \\t\\r\\n\\v\\f]` and therefor matches word characters like `d`. <br>\n",
    "The second one `[\\D\\S]` evaluates to `[^0-9]|[^ \\t\\r\\n\\v\\f]`. It therefor matches anything that is not a digit or not a whitespace character and as digits are not whitespace characters it matches any character.\n",
    "\n",
    "Also, there are a couple more abbreviations that only work in certain Regular Expression flavors. Because of this they are not widely used and it is best practice to omit them.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Expressions give convenient ways to quantify characters in expressions.\n",
    "\n",
    "| Quantifier | Meaning | Example Expression | Example Matches |\n",
    "|------------|---------|--------------------|-----------------|\n",
    "| `?`        | Zero or one occurrences | `a?b` | `b` or `ab`  |\n",
    "| `*`        | Zero or more occurrences | `a*b` | `b` or `ab` or `aab` (and so on) |\n",
    "| `+`        | One or more occurrences | `a+b` | `ab` or `aab` or `aaab` (and so on) |\n",
    "| `{n}`      | n of the preceding | `a{2}b` | `aab` |\n",
    "| `{n,m}`    | n to m of the preceding | `a{2,4}b` | `aab` or `aaab` or `aaaab` |\n",
    "| `{,m}`     | up to m of the preceding | `a{,3}b` | `b` or `ab` or `aab` or `aaab` |\n",
    "| `{n,}`     | n or more of the preceding | `a{3,}b` | `aaab` or `aaaab` or `aaaaab` (and so on) |\n",
    "\n",
    "These Quantifiers can also be used on character sets and [groups](#Groups) (described below).\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantifier Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Expression `[0-9]{1,3}` or `\\d{1,3}` matches any one to three digits, for example `123`, or `99`, or `7`. Keep in mind that the digit doesn't have to be the same. How to match only similar digits (like `999`), but not `123` will be shown later ([Back Reference Example](#Back-Reference-Example)).\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy vs Lazy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general all quantifiers in Regular Expressions are what is called greedy: They match as many characters as possible.\n",
    "\n",
    "For example the Expression `e\\w+` matches from each `e` to the end of the word. In the string `Regular Expressions are great fun` this would mean the matches are: `egular`, `essions` and `eat`.\n",
    "\n",
    "In order to prevent the greediness of the quantifier follow it with a `?` which makes it lazy - it matches only enough characters to create a valid match.\n",
    "\n",
    "In the example before the lazy Expression would be: `e\\w+?`\n",
    "\n",
    "On the same sample string this matches the following: `eg`, `es` and `ea`.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groups\n",
    "\n",
    "Parts of a Regular Expression can be grouped together by putting them inside of round brackets `()`. This is for example very useful to use quantifiers on words or multiple characters.\n",
    "\n",
    "For example suppose you want to create a Regular Expression that matches any of the  strings `Moneylaundry` and `Money`. A Regular Expression for this would be `Money(laundry)?`.\n",
    "Of course the Expression `Money|Moneylaundry` would in this case work as well but is bad practice. Strings (in this case `Money`) should not be repeated inside an Expression if possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using groups is very useful for another reason. The Regular Expression engine stores the text matched by the grouped expression in a separate container. This container can than be used in other places of the Regular Expression or to separate the output of the Expression into multiple parts like in the [example challenge](#Example-Challenge)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Regular Expression tester these groups can be seen in the Match Information section where for the example above you can see the Group 1 which matches laundry. The different groups are also highlighted in the text which helps for more complex expressions to find which part of the text is matched by what.\n",
    "\n",
    "<img src=\"regex101_group1.png\">\n",
    "\n",
    "The groups are numbered in order of their occurrence in the Regular Expression starting with 1. In some systems the group 0 is the whole match, but this is not consistent. The maximum group number is 99.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very powerful tool is the ability to reference back to groups. Imagine you want to check a text for doubled words. It is not feasible to create an Expression for every possible combination of two words. Instead you can use back reference.\n",
    "\n",
    "The Expression\n",
    "~~~\n",
    "\\b(\\w+)\\s+\\1\\b\n",
    "~~~\n",
    "will do exactly this.\n",
    "The `\\b` is an [Anchor Tag](#Anchors) that matches on a word boundary (beginning or end of a word). Anchor tags will be covered in more detail later.\n",
    "`(\\w+)` creates a group that matches one or more characters - you could say a word. This is followed by one ore more white spaces (`\\s+`). Up to here nothing new. The back reference is the `\\1` which means whatever was in group 1 has to be here as well to match. This means only if a word is followed by itself this will result in a match.\n",
    "\n",
    "The general syntax for a back reference is `\\x` or `\\xx` where `x` and `xx` are the group numbers referenced. Leading 0s are not allowed in this.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back Reference Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another good example for this is the [Quantifier Example](#Quantifier-Example) used above.\n",
    "\n",
    "As shown the Expression `\\d{1,3}` matches any one to three digits, for example 123, or 99, or 7. But what about only matching the same digits (like 999)?\n",
    "\n",
    "This can be achieved using Back Reference:\n",
    "\n",
    "The Expression `(\\d)\\1{1,2}` matches any number composed of two or three same digits like `888` or `77`.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A feature that improves readability a great deal is to name groups. Having many numbered groups in an Expression makes it easy to loose track and as they are numbered left-to-right editing the Expression later can be dangerous.\n",
    "\n",
    "It is therefor best practice to always name groups that will be used in another place.\n",
    "\n",
    "The syntax to do so is:\n",
    "~~~\n",
    "(?P<name>Expression)\n",
    "~~~\n",
    "where `name` can be any unique name and `Expression` is the Regular Expression to be grouped as before.\n",
    "\n",
    "This group name can than be used in Back References. Instead of `\\GroupNumber` the syntax is `(?P=name)` where name is the group name to be matched. This is a bit longer, but much easier to understand if the Expression gets longer.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Group Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a named group for the [Back Reference Example](#Back-Reference-Example) is a bit longer, but much easier to read:\n",
    "~~~\n",
    "(?P<FirstDigit>\\d)(?P=FirstDigit){1,2}\n",
    "~~~\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Match Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use a group just to group Expressions together, but don't want it to appear in the list of matches you can use the following syntax to make it a Non-Match Group:\n",
    "~~~\n",
    "(?:Expression)\n",
    "~~~\n",
    "where `Expression` is the Regular Expression to be grouped.\n",
    "\n",
    "This group behaves as any other group, but won't be shown in the list of matches and won't be included in the numbering of groups.\n",
    "\n",
    "In the Expression `(Hello)(?:MBAN)(Cohort)` the group number for `Hello` is `1` and the group number for `Cohort` is `2`.\n",
    "\n",
    "Non-Match Groups can therefor not be used in Back References.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another very powerful thing groups can be used for is to create something that works like an if-else statement.\n",
    "\n",
    "The syntax is:\n",
    "~~~\n",
    "(?(n)yes|no)\n",
    "~~~\n",
    "If capturing group `n` (can be the group name or number) was matched so far the Regular Expression matches the pattern before the vertical bar (`yes`). Otherwise, it matches the pattern after the vertical bar (`no`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If for example you want to ensure the formating of a telephone number. If it starts with a `+` or `00` this should be followed by a country code. If it doesn't it should start with a single `0`. Assume you want to match either the country code or the leading zero.\n",
    "~~~\n",
    "(?P<countryCode>\\+|00)? # match either + or 00 in the named group. This group can be\n",
    "                        # occurring zero or one times\n",
    "(?(countryCode)\\d{2}|0) # If the + or 00 were matched expect two digits for the\n",
    "                        # country code, else expect a 0\n",
    "~~~\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive Lookahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A positive lookahead enables you to only match a certain pattern if it is followed by another pattern which is not part of the overall match.\n",
    "\n",
    "Assume you want to match `foo` only if it is followed by `bar` like in the word `foobar`. You don't want the expression to match the `foo` in `food` for example.\n",
    "\n",
    "This requires the Regular Expression to look ahead and match at the current position if the the part ahead looks right (positive).\n",
    "\n",
    "The syntax to do this is for the example above\n",
    "~~~\n",
    "foo(?=bar)\n",
    "~~~\n",
    "This Expression only matches the letters `foo` if they are directly followed by the letters `bar`.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Lookahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative Lookahead is the exact opposite. You only want the first expression to match if it is not followed by the second.\n",
    "\n",
    "You only want to match `foo` if it is not followed by `bar`:\n",
    "~~~\n",
    "foo(?!bar)\n",
    "~~~\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookbehind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive Lookbehind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive Lookbehind means compared to Positive Lookahead the Regular Expression is not looking at the characters following, but at the preceding characters.\n",
    "\n",
    "Assume you want to match the word `bar` only if it is preceded by `foo` and not if preceded by `whiskey `:\n",
    "~~~\n",
    "(?<=foo)bar\n",
    "~~~\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Lookbehind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative Lookbehind is the opposite of Positive Lookbehind. You only match something that is not preceded by something else.\n",
    "\n",
    "Assume you want to match the word `bar` only if it is not preceded by `foo`:\n",
    "~~~\n",
    "(?<!foo)bar\n",
    "~~~\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different to everything covered so far Anchors don't match any character, but a position. They are used to direct the match to a certain position in a string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of String"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure a Regular Expression only matches at the start of the string use the `^` anchor.\n",
    "If [multiline mode](#Multiline) (modes are explained later) is selected this will also match the start of each line.\n",
    "\n",
    "Where the expression `a` matches any `a` in a given string you can anchor it to match only `a`s at the beginning of a string by using the caret: `^a`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to the `^` anchor is using `\\A`. This is not affected by multiline mode and only matches the start of the string regardless.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of String"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the start of string anchor there is also the end of string anchor `$`. The end of string anchor matches at the end of the string and if [multiline mode](#Multiline) is selected also at the end of each line.\n",
    "\n",
    "Example:\n",
    "\n",
    "The Regular Expression `\\w+$` matches only the `rocks` of the string `MBAN rocks`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to the `$` anchor is using `\\Z`. This is not affected by multiline mode and only matches the end of the string regardless.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to match a character only if it occurs at a word boundary (beginning or end of a word) use the word boundary anchor `\\b`.\n",
    "\n",
    "To be more specific `\\b` matches where either `\\w` ([word Character](#Abbreviated-Character-Sets)) is immediately followed by `\\W` (non-word Character) or `\\W` is directly followed by `\\w`.\n",
    "\n",
    "An example of this is to match all first letters of a sentence: `\\b\\w`\n",
    "\n",
    "If you would try to use `\\W\\w` instead this would also match the space before the letter which is not intended.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-word boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The opposite of word boundaries are non-word boundaries. They match between two characters matched by `\\w`. Keep in mind that they don't match between multiple non-word (`\\W`) characters.\n",
    "\n",
    "An example is to match the letter `s` only if it is in the middle of a word: `\\Bs\\B`.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make Regular Expressions more readable it is good practice to add comments.\n",
    "This can be done in a similar way to Python by using the `#` everything after the `#` until the end of the line will be considered as comment.\n",
    "\n",
    "In order for this to work the [ignore whitespace](#Ignore-Whitespace) mode must be enabled.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Expression modes change the overall behavior of the Regular Expression Engine. They are also called Flags or Modifiers. Any number of flags can be switched on at the same time.\n",
    "\n",
    "In the flavors used in Python and R they can only set globally for the whole Expression and not as in some other flavors locally for parts of an Expression.\n",
    "\n",
    "Their names can be very confusing and don't always match what common sense would make of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Regular Expression Tester you can see and select the modes on the right hand side of the Expression. You can change them by clicking the flag symbol.\n",
    "\n",
    "<img src=\"regex101-modes.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you use Regular Expressions programmatically there are different ways to switch the modes. Some functions enable you to pass the modes as additional argument for others you have to use the [global mode modifiers](#Global-Mode-Modifiers). In the section explaining how to use Regular Expressions in Python and R this is explained for each function described.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The global Regular Expression Mode tells the Regular Expression Engine not to stop after finding the first match in the string, but to continue.\n",
    "\n",
    "It is by standard switched on in Python as well as in R.\n",
    "\n",
    "The flag for the global mode is `g`.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multiline mode only influences where the `^` and `$` [anchors](#Anchors) match. If multiline is switched on they match at the beginning/end of each line. If switched off they behave like the `A` and `Z` anchors and only match at the beginning/end of the whole string.\n",
    "\n",
    "This mode is by standard switched on in Python and R.\n",
    "\n",
    "The flag for the multiline mode is `m`.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Insensitive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The case insensitive mode makes capital letters match lowercase letters and vise versa.\n",
    "\n",
    "The flag for the case insensitive mode is `i`.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore Whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ignore whitespace mode tells the engine to ignore all whitespace in the Expression and allow for [comments](#Comments). If you need to include a space character in your Expression, it must now be escaped `\\ `.\n",
    "\n",
    "The flag for the ignore whitespace mode is `x`.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Line mode is the most strangely named mode as one could be assume it is the opposite of Multiline mode. This is not the case. Both modes have nothing to do with each other and it is completely valid to have both selected at the same time.\n",
    "\n",
    "Single Line mode enables the `.` wildcard to also match `\\n` newline characters. This means that the string could be imagined as a single line string which is where the name comes from.\n",
    "\n",
    "The flag for the single line mode is `s`.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable Unicode Support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Enable Unicode Support mode switches strings to be treated as UTF-16, which means that unicode characters will also be included in `[a-z]` ranges, and in escape sequences.\n",
    "\n",
    "Keep in mind that Python 3 is going to treat your whole script as unicode by default, therefore using this flag would be redundant. Python 2 requires this flag to turn on unicode support.\n",
    "\n",
    "Only this flag or the Restrict Matches to ASCII flag can be activated at the same time.\n",
    "\n",
    "The flag for the Enable Unicode Support mode is `u`.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restrict Matches to ASCII"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Restrict Matches to ASCII mode restricts the Regular Expression to only match based on ASCII characters instead of full Unicode matching. This applies to the `[a-z]` range and escape sequences.\n",
    "\n",
    "This flag does not exist in Python2, as by default your script is parsed in ascii mode. In Python3 this will behave as described.\n",
    "\n",
    "Only this flag or the Enable Unicode Support flag can be activated at the same time.\n",
    "\n",
    "The flag for the Restrict Matches to ASCII mode is `a`.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Mode Modifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to set the modes for a Regular Expression use the mode-modifier as first part of the Expression.\n",
    "\n",
    "In order to set flag `s` the syntax is `(?s)`. If you want to set multiple flags you can just put them together like `(?imsxa)`. The order of flags doesn't matter.\n",
    "\n",
    "Note: You can't set the `g` global flag and the `u` unicode flag this way.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Expressions in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escaping in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python strings use the `\\` to escape characters just like Regular Expressions do. This leads to the need to double escape:\n",
    "\n",
    "The Expression `\\n` in a Python string needs to be written as `\\\\n`. Even worse, the Expression to match a single literal backslash `\\\\` in Python needs to be written as `\\\\\\\\`.\n",
    "\n",
    "This quickly gets confusing and hard to read. Fortunately, Python has raw-strings that ignore any escapes. They are used by preceding the string with the letter `r`:\n",
    "~~~\n",
    "r'my String does not escape the \\\\'\n",
    "r\"my second String \\n has a line break\"\n",
    "r'''my third string has a delimiter \" inside\n",
    "    and is multiline'''\n",
    "~~~\n",
    "It is important to observe that you can't use the delimiter you use for the string (`'`,`\"`,`'''`) inside the Expression as there is no way to escape it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from print:\n",
      "my String does not escape the \\\\\n",
      "\n",
      "How the String looks internally:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'my String does not escape the \\\\\\\\'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FirstString = r'my String does not escape the \\\\'\n",
    "SecondString = r\"my second String \\n has a line break\"\n",
    "ThirdString = r'''my third string has a delimiter \" inside\n",
    "              and is multiline'''\n",
    "print(\"Output from print:\")\n",
    "print(FirstString + \"\\n\")\n",
    "print(\"How the String looks internally:\")\n",
    "FirstString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the output from the print with the display of the variable. You can see that internally by using the `r` Python automatically escapes the string. The print command than interprets the escaped string and displays it the intended way.\n",
    "\n",
    "On the other hand, if you just display the variable content you will see that the `\\\\` at the end of the string is properly escaped.\n",
    "\n",
    "It is important to keep this in mind when building Regular Expressions in code.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The re Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The re package is part of the standard installation of both Python 3 and Python 2. It provides a Regular Expression engine able to use them on basic strings.\n",
    "\n",
    "To import the Re package use:\n",
    "\n",
    "~~~\n",
    "import re\n",
    "~~~\n",
    "\n",
    "The official package documentation can be found at https://docs.python.org/3/library/re.html#module-re\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modes in re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most re functions you can give the Regular Expression modes as a set of flags with the optional argument:\n",
    "~~~\n",
    "flags = ...\n",
    "~~~\n",
    "\n",
    "this argument expects a number between 0 and 511 (9-bit). This is because there are 9 (the 1st is a debug flag and the 8th one is experimental and not fully supported - both will not be covered here) mode flags that the re package supports. Each mode flag sets one bit in this 9-bit number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "format((re.A), 'b')": "100000000",
     "format((re.I), 'b')": "10",
     "format((re.L), 'b')": "100",
     "format((re.M), 'b')": "1000",
     "format((re.S), 'b')": "10000",
     "format((re.U), 'b')": "100000",
     "format((re.X), 'b')": "1000000",
     "int(bin(re.A), 2)": "256",
     "int(bin(re.I), 2)": "2",
     "int(bin(re.L), 2)": "4",
     "int(bin(re.M), 2)": "8",
     "int(bin(re.S), 2)": "16",
     "int(bin(re.U), 2)": "32",
     "int(bin(re.X), 2)": "64"
    }
   },
   "source": [
    "In order to make setting and remembering them easier they all have a named constant and another short version constant that can be used. It is unfortunate that the naming of the flags in Python partly differs from the Regular Expression flag names.\n",
    "\n",
    "\n",
    "| Mode | Flag | Flag short | In-line Flag | Binary | Integer | Comment |\n",
    "| ---- | ---- | ---------- | ------------ | ------ | ------- | ------- |\n",
    "| [Case Insensitive](#Case-Insensitive) | `re.IGNORECASE` | `re.I` | `(?i)` | {{format((re.I), 'b')}} | {{int(bin(re.I), 2)}} | |\n",
    "| Locale | `re.LOCALE` | `re.L` | `(?L)` | {{format((re.L), 'b')}} | {{int(bin(re.L), 2)}} | Don't use |\n",
    "| [Multiline](#Multiline) | `re.MULTILINE` | `re.M` | `(?m)` | {{format((re.M), 'b')}} | {{int(bin(re.M), 2)}} | |\n",
    "| [Single Line](#Single-Line) | `re.DOTALL` | `re.S` | `(?s)` | {{format((re.S), 'b')}} | {{int(bin(re.S), 2)}} | |\n",
    "| [Unicode Support](#Enable-Unicode-Support) | `re.UNICODE` | `re.U` | `(?u)` | {{format((re.U), 'b')}} | {{int(bin(re.U), 2)}} | Default in Python 3.7 |\n",
    "| [Ignore Whitespace](#Ignore-Whitespace) | `re.VERBOSE` | `re.X` | `(?x)` | {{format((re.X), 'b')}} | {{int(bin(re.X), 2)}} | |\n",
    "| [ASCII](#Restrict-Matches-to-ASCII) | `re.ASCII` | `re.A` | `(?a)` | {{format((re.A), 'b')}} | {{int(bin(re.A), 2)}} | |\n",
    "\n",
    "The Local mode is not part of the general Regular Expression syntax, but is implemented in the Python re package. It makes characters be matched in a case-insensitive way based on the computers region (keyboard and language settings). It is discouraged to use this mode as its implementation is unreliable ([package description](#https://docs.python.org/3/library/re.html#re.LOCALE)). Use Unicode mode instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "format((re.I | re.M), 'b')": "1010",
     "int(bin((re.I | re.M)), 2)": "10"
    }
   },
   "source": [
    "As the `flag = ...` argument only accepts one number these flags need to be combined into one number depending on what combination of flags to be set.\n",
    "\n",
    "The easiest way to do this is by using the Python binary-or operator `|` which in algebraic terms would be the same as performing an addition of both numbers:\n",
    "\n",
    "`re.I | re.M` = {{format((re.I | re.M), 'b')}} (binary) = {{int(bin((re.I | re.M)), 2)}} (decimal)\n",
    "\n",
    "The important bit to remember is to set the flags by combining them using the `|` operator. But using the number instead would work as well.\n",
    "\n",
    "Example:\n",
    "\n",
    "~~~\n",
    "flags = re.U | re.IGNORECASE | re.M\n",
    "~~~\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search scans through a string looking for the first location where the Expression pattern matches.\n",
    "\n",
    "It returns either a [match object](#Match-Object) if it found a match or `none`.\n",
    "\n",
    "Syntax:\n",
    "~~~\n",
    "re.search(pattern,   # the Regular Expression Pattern\n",
    "          string,    # the string for the Pattern to be used on\n",
    "          flags = 0) # the Regular Expression modes (default: no mode selected)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re.match()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match works like search, but only attempts to match at the beginning of the string. Match is the same as adding `\\A` to the beginning of the Regular Expression and using search.\n",
    "\n",
    "It returns either a [match object](#Match-Object) if it found a match or `none`.\n",
    "\n",
    "Syntax:\n",
    "~~~\n",
    "re.match(pattern,   # the Regular Expression Pattern\n",
    "         string,    # the string for the Pattern to be used on\n",
    "         flags = 0) # the Regular Expression modes (default: no mode selected)\n",
    "~~~\n",
    "\n",
    "Note that even in MULTILINE mode, re.match() will only match at the beginning of the string and not at the beginning of each line.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re.fullmatch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns a [match object](#Match-Object) only if the whole input string is matched by the pattern, otherwise `none`.\n",
    "\n",
    "This can be very useful to check text inputs using Regular Expressions.\n",
    "\n",
    "Syntax:\n",
    "~~~\n",
    "re.fullmatch(pattern,   # the Regular Expression Pattern\n",
    "             string,    # the string for the Pattern to be used on\n",
    "             flags = 0) # the Regular Expression modes (default: no mode selected)\n",
    "~~~\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re.findall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to retrieve all matches from a string use re.findall().\n",
    "\n",
    "Syntax:\n",
    "~~~\n",
    "re.findall(pattern,   # the Regular Expression Pattern\n",
    "           string,    # the string for the Pattern to be used on\n",
    "           flags = 0) # the Regular Expression modes (default: no mode selected)\n",
    "~~~\n",
    "\n",
    "This will return a list of all non-overlapping matches of the Expression. If [matching groups](#Groups) are present in the Expression a list of the groups will be returned.\n",
    "\n",
    "Non-overlapping means that as the string is matched from left-to-right the next match can only start after the previous is finished.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re.finditer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finditer returns a an iterator object (https://www.w3schools.com/python/python_iterators.asp) that enables to loop through all matches (similar to [re.findall](#re.findall())).\n",
    "\n",
    "Syntax:\n",
    "~~~\n",
    "re.finditer(pattern,   # the Regular Expression Pattern\n",
    "            string,    # the string for the Pattern to be used on\n",
    "            flags = 0) # the Regular Expression modes (default: no mode selected)\n",
    "~~~\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hult\n",
      "MBAN\n",
      "rocks\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "for m in re.finditer(r'\\w+', 'Hult MBAN rocks!'):\n",
    "    print(m.group())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re.sub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub performs a search and replace operation on a string. Returns a string with matches of the Expression replaced by the replacement string.\n",
    "\n",
    "Syntax:\n",
    "~~~\n",
    "re.sub(pattern,     # the Regular Expression Pattern\n",
    "       replacement, # the String to be used as replacement for the matches.\n",
    "                    # Can also be a function as described below\n",
    "       string,      # the string for the Pattern to be used on\n",
    "       count = 0,   # the maximum number of pattern occurrences to be replaced (default: unlimited)\n",
    "       flags = 0)   # the Regular Expression modes (default: no mode selected)\n",
    "~~~\n",
    "\n",
    "Keep in mind that for the replacement string backslashes `\\` need to be escaped just like in Regular Expressions. If you want to use the path `'c:\\windows'` as replacement escape it as: `r'c:\\\\windows'`\n",
    "\n",
    "You can also use groups matched by the pattern in the replacement string. To replace the matched text with the 2nd group of the pattern use `\\2` as replacement string. In order to combine a numbered group with a digit in the replacement string use `\\g<2>8` for example as `\\28` would be interpreted as group 28. You can also use named groups, for example `\\g<name>`\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A lot of students enjoy the MBAN at Hult International Business School. Hult International Business School is a business school.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.sub(r'(Hult)', # the Expression that matches the function definition\n",
    "       r'\\1 International Business School',          # \n",
    "       'A lot of students enjoy the MBAN at Hult. Hult is a business school.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If replacement is a function, it is called for every non-overlapping occurrence of the pattern. The function needs to a single match object argument, and return a replacement string.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 + 3 != +3 - 1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def myReplacementFunction(matchobj):\n",
    "    if matchobj.group(0) == '-':\n",
    "        return '+'\n",
    "    else:\n",
    "        return '-'\n",
    "re.sub(r'[+-]',\n",
    "       myReplacementFunction,\n",
    "       '1 - 3 != -3 + 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split is used to split a string into multiple parts by the occurrence of a pattern (Regular Expression). It returns a list of the parts of the original string.\n",
    "\n",
    "The syntax is:\n",
    "~~~\n",
    "re.split(pattern,      # the Regular Expression Pattern\n",
    "         string,       # the string for the Pattern to be used on\n",
    "         maxsplit = 0, # the maximum number of splits to be performed (0 means no limit)\n",
    "         flags = 0)    # the Regular Expression modes (default: no mode selected)\n",
    "~~~\n",
    "\n",
    "If [capturing groups](#Groups) are used the output of split includes the text captured by the groups' Expressions.\n",
    "\n",
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hult', 'MBAN', 'rocks', '']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "print(re.split(r'\\W+', 'Hult MBAN rocks!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the example above is a list of 4 strings as the pattern `\\W+` is matched by the `!` at the end of the input string. This creates a 3rd split between the word `rocks` and the end of the string. For this reason the 4th output string is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hult', 'MBAN rocks!']\n",
      "['Hult', ' ', 'MBAN', ' ', 'rocks', '!', '']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "print(re.split(r'\\W+', 'Hult MBAN rocks!', 1))\n",
    "print(re.split(r'(\\W+)', 'Hult MBAN rocks!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use a Regular Expression multiple times it is best to compile it into a [Regular Expression Object](#Regular-Expression-Object). Internally all of the re methods compile the expression directly before use, so if an Expression is used repeatedly it is more efficient to compile it only once.\n",
    "\n",
    "The [Regular Expression Object](#Regular-Expression-Object) provides all the functions the re package does (except re.compile of course).\n",
    "\n",
    "The syntax is:\n",
    "~~~\n",
    "ExpressionObject = re.compile(pattern,   # the Regular Expression Pattern\n",
    "                              flags = 0) # the Regular Expression modes (default: no mode selected)\n",
    "~~~\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regular Expression Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiled regular expression objects support the following methods and attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RegExObject.search()\n",
    "\n",
    "Works like [re.search](#re.search()).\n",
    "~~~\n",
    "RegExObject.search(string,               # the string for the Pattern to be used on\n",
    "                   pos = 0,              # optional index in the string where the search is to start\n",
    "                   endpos = len(string)) # optional index in the string where to end the search\n",
    "~~~\n",
    "\n",
    "#### RegExObject.match()\n",
    "\n",
    "Works like [re.match](#re.match()).\n",
    "~~~\n",
    "RegExObject.match(string,               # the string for the Pattern to be used on\n",
    "                  pos = 0,              # optional index in the string where the search is to start\n",
    "                  endpos = len(string)) # optional index in the string where to end the search\n",
    "~~~\n",
    "\n",
    "#### RegExObject.fullmatch()\n",
    "\n",
    "Works like [re.fullmatch](#re.fullmatch()).\n",
    "~~~\n",
    "RegExObject.fullmatch(string,               # the string for the Pattern to be used on\n",
    "                      pos = 0,              # optional index in the string where the search is to start\n",
    "                      endpos = len(string)) # optional index in the string where to end the search\n",
    "~~~\n",
    "\n",
    "#### RegExObject.split()\n",
    "\n",
    "Works like [re.split](#re.split()).\n",
    "~~~\n",
    "RegExObject.split(string,\n",
    "                  maxsplit = 0)\n",
    "~~~\n",
    "\n",
    "#### RegExObject.findall()\n",
    "\n",
    "Works like [re.findall](#re.findall()).\n",
    "~~~\n",
    "RegExObject.findall(string,               # the string for the Pattern to be used on\n",
    "                    pos = 0,              # optional index in the string where the search is to start\n",
    "                    endpos = len(string)) # optional index in the string where to end the search\n",
    "~~~\n",
    "\n",
    "#### RegExObject.finditer()\n",
    "\n",
    "Works like [re.finditer](#re.finditer()).\n",
    "~~~\n",
    "RegExObject.finditer(string,               # the string for the Pattern to be used on\n",
    "                     pos = 0,              # optional index in the string where the search is to start\n",
    "                     endpos = len(string)) # optional index in the string where to end the search\n",
    "~~~\n",
    "\n",
    "#### RegExObject.Sub()\n",
    "\n",
    "Works like [re.sub](#re.sub()).\n",
    "~~~\n",
    "RegExObject.sub(replacement,\n",
    "                string,\n",
    "                count = 0)\n",
    "~~~\n",
    "\n",
    "#### RegExObject.Flags\n",
    "The regex matching flags. This is a combination of the flags given to compile(), any (?...) inline flags in the pattern, and implicit flags such as UNICODE if the pattern is a Unicode string.\n",
    "\n",
    "#### RegExObject.Groups\n",
    "The number of capturing groups in the pattern.\n",
    "\n",
    "#### RegExObject.Groupindex\n",
    "A dictionary mapping any symbolic group names defined by (?P<id>) to group numbers. The dictionary is empty if no symbolic groups were used in the pattern.\n",
    "\n",
    "#### RegExObject.Pattern\n",
    "The pattern string from which the pattern object was compiled.\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re.escape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to programatically escape apecial characters in a patter you can use the function re.escape. This is especially useful if you want to match an arbitrary literal string that may contain [special characters](#Special-Characters) like a path or filename.\n",
    "\n",
    "Syntax:\n",
    "~~~\n",
    "re.escape(string)\n",
    "~~~\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\\\temp\\\\test\\.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "print(re.escape(r'c:\\temp\\test.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods like re.search() return match objects. These contain further information about the match.\n",
    "\n",
    "The most important feature is that they always have a boolean value of `True` which means they can be used in if-statements to check if the Regular Expression found a match and only in that case do something with it.\n",
    "\n",
    "Example:\n",
    "~~~\n",
    "match = re.search(pattern, string)\n",
    "if match:\n",
    "    # do something with the match here\n",
    "~~~\n",
    "\n",
    "Match Objects have a number of useful attributes and methods. The following are only the most commonly used ones. For the full list refer to the [documentation](https://docs.python.org/3/library/re.html#match-objects).\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Match.group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns one or more groups of the match object.\n",
    "\n",
    "Syntax:\n",
    "~~~\n",
    "match.group([group1, ...])\n",
    "~~~\n",
    "\n",
    "If the argument is a single group it will return a string. In case of multiple groups it returns a tuple. The argument can either be one or multiple group numbers or group names. You can't mix group names and numbers.\n",
    "\n",
    "To return the whole match use `match.group()` without argument or select group 0 (`match.group(0)`).\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Name:\n",
      "Max\n",
      "\n",
      "Last Name:\n",
      "Mustermann\n",
      "\n",
      "Group 1:\n",
      "Max\n",
      "\n",
      "Group 2:\n",
      "Mustermann\n",
      "\n",
      "Group 0:\n",
      "Max Mustermann\n",
      "\n",
      "no group:\n",
      "Max Mustermann\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "m = re.match(r\"(?P<first_name>\\w+) (?P<last_name>\\w+)\", \"Max Mustermann\")\n",
    "print('First Name:')\n",
    "print(m.group('first_name') + '\\n')\n",
    "print('Last Name:')\n",
    "print(m.group('last_name') + '\\n')\n",
    "print('Group 1:')\n",
    "print(m.group(1) + '\\n')\n",
    "print('Group 2:')\n",
    "print(m.group(2) + '\\n')\n",
    "print('Group 0:')\n",
    "print(m.group(0) + '\\n')\n",
    "print('no group:')\n",
    "print(m.group() + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Match.groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to `Match.group()`, but returns all groups of the match.\n",
    "\n",
    "Syntax:\n",
    "~~~\n",
    "Match.groups(default = None)\n",
    "~~~\n",
    "\n",
    "The default argument specifies what value groups that where not part of the match (like optional groups) will be given in the output. By default this value is set to none.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second group defaults to None:\n",
      "('24', None)\n",
      "\n",
      "\n",
      "Second group defaults to \"0\":\n",
      "('24', '0')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "m = re.match(r\"(\\d+)\\.?(\\d+)?\", \"24\")\n",
    "print('Second group defaults to None:')\n",
    "print(m.groups())\n",
    "print('\\n')\n",
    "print('Second group defaults to \"0\":')\n",
    "print(m.groups('0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Match.groupdict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the named groups of the match as a dictionary with the group-name as key.\n",
    "\n",
    "Syntax:\n",
    "~~~\n",
    "Match.groupdict(default = none)\n",
    "~~~\n",
    "\n",
    "The default argument specifies what value groups that where not part of the match (like optional groups) will be given in the output. By default this value is set to none.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_name': 'Max', 'last_name': 'Mustermann', 'age': None}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "m = re.match(r\"(?P<first_name>\\w+) (?P<last_name>\\w+)(?P<age>\\d+)?\", \"Max Mustermann\")\n",
    "print(m.groupdict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Match.start / Match.end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the start/end indices of the string matched by the group.\n",
    "\n",
    "Syntax:\n",
    "~~~\n",
    "Match.start(group)\n",
    "Match.end(group)\n",
    "~~~\n",
    "\n",
    "If no group argument is given this defaults to group 0 (whole match).\n",
    "\n",
    "Example:\n",
    "Remove \"oogle\" from E-Mail address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test@gmail.com\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "email = \"test@googlemail.com\"\n",
    "m = re.search(\"oogle\", email)\n",
    "print(email[:m.start()] + email[m.end():])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some functions of the Pandas package very conveniently directly support Regular Expressions. This is very useful when working on text data that is part of a DataFrame or Series.\n",
    "\n",
    "The methods that support Regular Expressions are based on Series objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series.str.contains()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contains function tests if a pattern is contained in the rows of a pd.Series. It ignores the position of the pattern in the row element like [re.search](#re.search()) does. It returns a Series of boolean values.\n",
    "\n",
    "The syntax is:\n",
    "~~~\n",
    "Series.str.contains(pattern,      # The pattern to be matched\n",
    "                    case = True,  # optional. If True match case sensitive.\n",
    "                    flags = 0,    # optional. The Regular Expression modes - set like in re-package\n",
    "                                  # (remember to import the re-package for this)\n",
    "                                  # The flag 're.I' will overwrite the case = True parameter\n",
    "                    na = NaN,     # optional. Missing values will be filled with this value\n",
    "                                  # (NaN, True, False)\n",
    "                    regex = True) # optional. Use Regular Expression for the pattern.\n",
    "                                  # If false the pattern will be matched literally.\n",
    "~~~\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "5      NaN\n",
      "dtype: object\n",
      "\n",
      "\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "5    False\n",
      "dtype: bool\n",
      "\n",
      "\n",
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3     True\n",
      "4    False\n",
      "5      NaN\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "s = pd.Series(['75', 'awesome', 'Hult', 'MBAN', 'students', np.NaN])\n",
    "print(s.str.contains('a|hu',\n",
    "                     case = True,\n",
    "                     regex = True))\n",
    "print('\\n')\n",
    "print(s.str.contains('a|hu',\n",
    "                     case = True,\n",
    "                     regex = True,\n",
    "                     na = False))\n",
    "print('\\n')\n",
    "print(s.str.contains('a|hu',\n",
    "                     case = True,\n",
    "                     regex = True,\n",
    "                     flags = re.I))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series.str.match()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The match function tests if a pattern matches the rows of a pd.Series from the first character on. It works similar to applying [re.match](#re.match()) to each row. It returns a Series of boolean values. Unlike with [str.contains](#Series.str.contains()) there is no regex parameter. Regular Expressions are always used.\n",
    "\n",
    "The syntax is:\n",
    "~~~\n",
    "Series.str.match(pattern,      # The pattern to be matched\n",
    "                 case = True,  # optional. If True match case sensitive.\n",
    "                 flags = 0,    # optional. The Regular Expression modes - set like in re-package\n",
    "                               # (remember to import the re-package for this)\n",
    "                               # The flag 're.I' will overwrite the case = True parameter\n",
    "                 na = NaN)     # optional. Missing values will be filled with this value\n",
    "                               # (NaN, True, False)\n",
    "~~~\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "5      NaN\n",
      "dtype: object\n",
      "\n",
      "\n",
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3     True\n",
      "4     True\n",
      "5    False\n",
      "dtype: bool\n",
      "\n",
      "\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3     True\n",
      "4     True\n",
      "5      NaN\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "s = pd.Series(['Hult', 'MBAN', 'MBA', 'MbAs', 'MBAN ', np.NaN])\n",
    "print(s.str.match('MBA',\n",
    "                  case = True))\n",
    "print('\\n')\n",
    "print(s.str.match(r'\\w+BA',\n",
    "                  case = False,\n",
    "                  na = False))\n",
    "print('\\n')\n",
    "print(s.str.match(r'MBA\\w',\n",
    "                  case = True,\n",
    "                  flags = re.I))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series.str.findall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The findall function returns a Series containing all occurrences of a pattern in a pd.Series. It is equivalent to applying [re.findall](#re.findall()) to every row of the Series.\n",
    "\n",
    "Syntax:\n",
    "~~~\n",
    "Series.str.findall(pattern,   # The pattern to be matched\n",
    "                   flags = 0) # optional. The Regular Expression modes - set like in re-package\n",
    "                              # (remember to import the re-package for this)\n",
    "~~~\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      []\n",
      "1    [BA]\n",
      "2    [BA]\n",
      "3      []\n",
      "4    [BA]\n",
      "5     NaN\n",
      "dtype: object\n",
      "\n",
      "\n",
      "0      []\n",
      "1    [BA]\n",
      "2    [BA]\n",
      "3    [bA]\n",
      "4    [BA]\n",
      "5     NaN\n",
      "dtype: object\n",
      "\n",
      "\n",
      "0    [s, s, s, S]\n",
      "1              []\n",
      "2              []\n",
      "3             [s]\n",
      "4              []\n",
      "5             NaN\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "s = pd.Series(['Hult International Business School', 'MBAN', 'MBA', 'MbAs', 'MBAN ', np.NaN])\n",
    "print(s.str.findall('BA'))\n",
    "print('\\n')\n",
    "print(s.str.findall('BA',\n",
    "                    flags = re.I))\n",
    "print('\\n')\n",
    "print(s.str.findall('s',\n",
    "                    flags = re.I))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series.str.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each row in the Series extracts the first match of the capture groups into a DataFrame/Series. Returns a DataFrame with one row for each row in the Series and one column for each capture group. If the capture groups are named these names will be used for the column names, otherwise the group numbers will be used.\n",
    "\n",
    "Syntax:\n",
    "~~~\n",
    "Series.str.extract(pattern,        # The pattern to be matched\n",
    "                   flags = 0,      # optional. The Regular Expression modes - set like in re-package\n",
    "                                   # (remember to import the re-package for this)\n",
    "                   expand = True)  # If True always return DataFrame with one column per group\n",
    "                                   # If False return a Series if there is only one group otherwise\n",
    "                                   # return a DataFrame\n",
    "~~~\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  letter digit\n",
      "0      a     1\n",
      "1      b     2\n",
      "2      c     3\n",
      "\n",
      "\n",
      "0      1\n",
      "1      2\n",
      "2    NaN\n",
      "dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "s = pd.Series(['a1', 'b2d4', 'c3'])\n",
    "print(s.str.extract(r'(?P<letter>[A-Z])(?P<digit>\\d)',\n",
    "                    flags = re.I))\n",
    "print('\\n')\n",
    "a = s.str.extract(r'[ab](\\d)',\n",
    "                  expand = False)\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series.str.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extractall is similar to [extract](#Series.str.extract()) but differs in so far, that it extracts all matches of every match group from a Series. It returns a DataFrame with with one row for each match, and one column for each group. Its rows have a MultiIndex with first levels that come from the subject Series. The last level is named ‘match’ and indexes the matches in each item of the Series. Any capture group names in the pattern will be used for column names; otherwise capture group numbers will be used. Optional groups that are not matched will return `NaN`.\n",
    "\n",
    "When each subject string in the Series has exactly one match, `extractall(pattern).xs(0, level = ’match’)` is the same as `extract(pattern)`.\n",
    "\n",
    "Syntax:\n",
    "~~~\n",
    "Series.str.extractall(pattern,   # The pattern to be matched\n",
    "                      flags = 0) # optional. The Regular Expression modes - set like in re-package\n",
    "                                 # (remember to import the re-package for this)\n",
    "~~~\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0\n",
      "  match   \n",
      "A 0      1\n",
      "  1      2\n",
      "B 0      1\n",
      "C 0      1\n",
      "  1      2\n",
      "  2      3\n",
      "  3      4\n",
      "\n",
      "\n",
      "        letter digit\n",
      "  match             \n",
      "A 0          a     1\n",
      "  1          a     2\n",
      "C 0          c     1\n",
      "  1          c     2\n",
      "  2          c     3\n",
      "  3          c     4\n",
      "\n",
      "\n",
      "        letter digit\n",
      "  match             \n",
      "A 0          a     1\n",
      "  1          a     2\n",
      "B 0        NaN     1\n",
      "C 0          c     1\n",
      "  1          c     2\n",
      "  2          c     3\n",
      "  3          c     4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "s = pd.Series([\"a1a2\", \"b1\", \"c1c2c3c4\"],\n",
    "              index=[\"A\", \"B\", \"C\"])\n",
    "print(s.str.extractall(r\"[a-z](\\d)\"))\n",
    "print('\\n')\n",
    "print(s.str.extractall(r\"(?P<letter>[ac])(?P<digit>\\d)\"))\n",
    "print('\\n')\n",
    "print(s.str.extractall(r\"(?P<letter>[ac])?(?P<digit>\\d)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series.str.replace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace occurrences of a pattern in the Series with some other string. Works similar to [re.sub](#re.sub()).\n",
    "\n",
    "Syntax:\n",
    "~~~\n",
    "Series.str.replace(pattern,      # The pattern to be matched\n",
    "                                 # Also accepts compiled re-object\n",
    "                   replacement,  # the String to be used as replacement for the matches.\n",
    "                                 # Can also be a function as described in re.sub()\n",
    "                   n = -1,       # optional. the maximum number of pattern occurrences to be replaced\n",
    "                                 # (-1: unlimited)\n",
    "                   case = True,  # optional. If True: case sensitive, if False case insensitive\n",
    "                                 # Can not be used if pattern is a compiled re-object\n",
    "                   flags = 0,    # optional. The Regular Expression modes - set like in re-package\n",
    "                                 # (remember to import the re-package for this)\n",
    "                                 # Can not be used if pattern is a compiled re-object\n",
    "                   regex = True) # optional. If True pattern will be treated as Regular Expression.\n",
    "                                 # If False pattern will be treated as literal string.\n",
    "~~~\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    bao 123\n",
      "1    bar baz\n",
      "2        NaN\n",
      "dtype: object\n",
      "\n",
      "\n",
      "0    oof 123\n",
      "1    rab zab\n",
      "2        NaN\n",
      "dtype: object\n",
      "\n",
      "\n",
      "0    123\n",
      "1    BAZ\n",
      "2    NaN\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "s = pd.Series(['foo 123', 'bar baz', np.nan])\n",
    "print(s.str.replace('f.',\n",
    "                    'ba',\n",
    "                    regex = True))\n",
    "print('\\n')\n",
    "print(s.str.replace(r'[a-z]+',\n",
    "                    lambda m: m.group(0)[::-1])) # reverse every lowercase alphabethic word\n",
    "print('\\n')\n",
    "print(s.str.replace(r\"(?P<one>\\w+) (?P<two>\\w+)\",\n",
    "                    lambda m: m.group('two').swapcase())) # extract second group and swap case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series.str.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counts the number of matches of a pattern in each row of the Series. Returns a Series containing the number the pattern is matched for each row of the original Series.\n",
    "\n",
    "Syntax:\n",
    "~~~\n",
    "Series.str.count(pattern,   # The pattern to be matched\n",
    "                 flags = 0) # optional. The Regular Expression modes - set like in re-package\n",
    "                            # (remember to import the re-package for this)\n",
    "~~~\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.0\n",
      "1    0.0\n",
      "2    2.0\n",
      "3    2.0\n",
      "4    NaN\n",
      "5    0.0\n",
      "6    1.0\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "0    1.0\n",
      "1    0.0\n",
      "2    3.0\n",
      "3    2.0\n",
      "4    NaN\n",
      "5    2.0\n",
      "6    1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "s = pd.Series(['A', 'B', 'Aaba', 'Baca', np.nan, 'CABA', 'cat'])\n",
    "print(s.str.count('a'))\n",
    "print('\\n')\n",
    "print(s.str.count('a',\n",
    "                  flags = re.I))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series.str.split() / Series.str.rsplit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split() and rsplit() split strings in the Series around given pattern. They work equivalent to [str.split()](https://docs.python.org/3/library/stdtypes.html#str.split) but use Regular Expressions. Also very similar to [re.split](#re.split()).\n",
    "\n",
    "Return either a DataFrame with one column for each split or a Series containing lists of strings.\n",
    "\n",
    "If the parameter n is not set to limit the splits split() and rsplit() are equivalent. If the number of splits allowed is less than the potential number of splits split() will start the splitting on the left of the String whereas rsplit() will start from the right.\n",
    "\n",
    "Syntax:\n",
    "~~~\n",
    "Series.str.count(pattern = ' ',  # optional. The pattern to be matched.\n",
    "                                 # if not specified will split at whitespace\n",
    "                 n = -1,         # optional. Maximum number of splits.\n",
    "                                 # None, 0 and -1 will return all splits\n",
    "                 expand = False) # Expand the splitted strings into separate columns.\n",
    "                                 # If True, return DataFrame expanding dimensionality.\n",
    "                                 # If False, return Series containing lists of strings.\n",
    "~~~\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split, n = -1\n",
      "0                         [this is a regular sentence]\n",
      "1    [https:, , docs.python.org, 3, tutorial, index...\n",
      "2                                                  NaN\n",
      "dtype: object\n",
      "\n",
      "\n",
      "rsplit, n = -1\n",
      "0                         [this is a regular sentence]\n",
      "1    [https:, , docs.python.org, 3, tutorial, index...\n",
      "2                                                  NaN\n",
      "dtype: object\n",
      "\n",
      "\n",
      "split, n = 2\n",
      "                            0     1                                      2\n",
      "0  this is a regular sentence  None                                   None\n",
      "1                      https:        docs.python.org/3/tutorial/index.html\n",
      "2                         NaN   NaN                                    NaN\n",
      "\n",
      "\n",
      "rsplit, n = 2\n",
      "                            0         1           2\n",
      "0  this is a regular sentence      None        None\n",
      "1   https://docs.python.org/3  tutorial  index.html\n",
      "2                         NaN       NaN         NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "s = pd.Series([\"this is a regular sentence\",\n",
    "               \"https://docs.python.org/3/tutorial/index.html\",\n",
    "               np.nan])\n",
    "print('split, n = -1')\n",
    "print(s.str.split(r\"/\",\n",
    "                  n = -1,\n",
    "                  expand = False))\n",
    "print('\\n')\n",
    "print('rsplit, n = -1')\n",
    "print(s.str.rsplit(r\"/\",\n",
    "                   n = -1,\n",
    "                   expand = False))\n",
    "print('\\n')\n",
    "print('split, n = 2')\n",
    "print(s.str.split(r\"/\",\n",
    "                  n = 2,\n",
    "                  expand = True))\n",
    "print('\\n')\n",
    "print('rsplit, n = 2')\n",
    "print(s.str.rsplit(r\"/\",\n",
    "                   n = 2,\n",
    "                   expand = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regex Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regex package which is not part of the default Python installation offers everything that the re-package does but expands on this functionality. It is fully backwards compatible to the re-package.\n",
    "\n",
    "To install the regex package run the following in a terminal:\n",
    "~~~\n",
    "conda install regex\n",
    "~~~\n",
    "\n",
    "For details on the package and its functionality refer to https://pypi.org/project/regex\n",
    "\n",
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 1\n",
       "[1] 1 3 4\n",
       "[1] \"abc\"   \"cba a\" \"aa\"   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "print(grep(\"a+\",\n",
    "           \"bcad\",\n",
    "           perl = TRUE,\n",
    "           value = FALSE))\n",
    "print(grep(\"a+\",\n",
    "           c(\"abc\", \"def\", \"cba a\", \"aa\"),\n",
    "           perl = TRUE,\n",
    "           value = FALSE))\n",
    "print(grep(\"a+\",\n",
    "           c(\"abc\", \"def\", \"cba a\", \"aa\"),\n",
    "           perl = TRUE,\n",
    "           value = TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]  TRUE FALSE  TRUE  TRUE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "print(grepl(\"a+\",\n",
    "            c(\"abc\", \"def\", \"cba a\", \"aa\"),\n",
    "            perl = TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 1 2\n",
       "[1] \"lasy\"   \"2lazy4\"\n",
       "[1] \"lasy\"   \"2lazy4\" \"lz\"    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "print(agrep(\"laz+\",\n",
    "            c(\"lasy\", \"2lazy4\", \"xyz xyz\"),\n",
    "            fixed = FALSE))\n",
    "print(agrep(\"laz+\",\n",
    "            c(\"lasy\", \"2lazy4\", \"xyz xyz\"),\n",
    "            max.distance = 0.05,\n",
    "            fixed = FALSE,\n",
    "            value = TRUE))\n",
    "print(agrep(\"laz\",\n",
    "            c(\"lasy\", \"2lazy4\", \"xyz xyz\", \"lz\"),\n",
    "            max.distance = list(insertions = 1,\n",
    "                                deletions = 0,\n",
    "                                substitutions = 2),\n",
    "            fixed = FALSE,\n",
    "            value = TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]  TRUE  TRUE FALSE FALSE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "print(agrepl(\"lazy\",\n",
    "             c(\"lasy\", \"2lazy4\", \"xyz xyz\", \"lz\"),\n",
    "             fixed = FALSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1]]\n",
       "[1] \"http:\" \"\"      \"www\"   \"hult\"  \"edu\"  \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "print(strsplit(\"http://www.hult.edu\",\n",
    "               \"[/\\\\.]\",\n",
    "               perl = TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]  1 -1  3  1  3\n",
       "attr(,\"match.length\")\n",
       "[1]  1 -1  1  2  3\n",
       "attr(,\"index.type\")\n",
       "[1] \"chars\"\n",
       "attr(,\"useBytes\")\n",
       "[1] TRUE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "print(regexpr(\"a+\", c(\"abc\", \"def\", \"cba a\", \"aa\", \"sdaaa\"), perl = TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1]]\n",
       "[1] 1\n",
       "attr(,\"match.length\")\n",
       "[1] 1\n",
       "attr(,\"index.type\")\n",
       "[1] \"chars\"\n",
       "attr(,\"useBytes\")\n",
       "[1] TRUE\n",
       "\n",
       "[[2]]\n",
       "[1] -1\n",
       "attr(,\"match.length\")\n",
       "[1] -1\n",
       "attr(,\"index.type\")\n",
       "[1] \"chars\"\n",
       "attr(,\"useBytes\")\n",
       "[1] TRUE\n",
       "\n",
       "[[3]]\n",
       "[1] 3 5\n",
       "attr(,\"match.length\")\n",
       "[1] 1 1\n",
       "attr(,\"index.type\")\n",
       "[1] \"chars\"\n",
       "attr(,\"useBytes\")\n",
       "[1] TRUE\n",
       "\n",
       "[[4]]\n",
       "[1] 1 4\n",
       "attr(,\"match.length\")\n",
       "[1] 2 3\n",
       "attr(,\"index.type\")\n",
       "[1] \"chars\"\n",
       "attr(,\"useBytes\")\n",
       "[1] TRUE\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "print(gregexpr(\"a+\", c(\"abc\", \"def\", \"cba a\", \"aa aaa\"), perl = TRUE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"regexpr:\"\n",
       "[1] \"a\"   \"a\"   \"aa\"  \"aaa\"\n",
       "[1] \"\\n\"\n",
       "[1] \"gregexpr:\"\n",
       "[[1]]\n",
       "[1] \"a\"\n",
       "\n",
       "[[2]]\n",
       "character(0)\n",
       "\n",
       "[[3]]\n",
       "[1] \"a\" \"a\"\n",
       "\n",
       "[[4]]\n",
       "[1] \"aa\"\n",
       "\n",
       "[[5]]\n",
       "[1] \"aaa\"\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "x <- c(\"abc\", \"def\", \"cba a\", \"aa\", \"sdaaa\")\n",
    "print(\"regexpr:\")\n",
    "m <- regexpr(\"a+\", x, perl=TRUE)\n",
    "print(regmatches(x, m))\n",
    "print(\"gregexpr:\")\n",
    "m <- gregexpr(\"a+\", x, perl=TRUE)\n",
    "print(regmatches(x, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"Original:\"\n",
       "[1] \"abc\"      \"def\"      \"cba a\"    \"aa Hallo\"\n",
       "[1] \"Surrounding first Group with z:\"\n",
       "[1] \"zazbc\"      \"def\"        \"cbzaz a\"    \"zaaz Hallo\"\n",
       "[1] \"Surrounding first Group with z and making it uppercase:\"\n",
       "[1] \"zAzbc\"      \"def\"        \"cbzAz a\"    \"zAAz Hallo\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "text <- c(\"abc\", \"def\", \"cba a\", \"aa Hallo\")\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Surrounding first Group with z:\")\n",
    "print(sub(\"(a+)\",\n",
    "          \"z\\\\1z\",\n",
    "          text,\n",
    "          perl = TRUE))\n",
    "print(\"Surrounding first Group with z and making it uppercase:\")\n",
    "print(sub(\"(a+)\",\n",
    "          \"z\\\\U\\\\1z\",\n",
    "          text,\n",
    "          perl = TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"Original:\"\n",
       "[1] \"abc\"      \"def\"      \"cba a\"    \"aa Hallo\"\n",
       "[1] \"Surrounding first Group with z:\"\n",
       "[1] \"zazbc\"        \"def\"          \"cbzaz zaz\"    \"zaaz Hzazllo\"\n",
       "[1] \"Surrounding first Group with z and making it uppercase:\"\n",
       "[1] \"zAzbc\"        \"def\"          \"cbzAz zAz\"    \"zAAz HzAzllo\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "text <- c(\"abc\", \"def\", \"cba a\", \"aa Hallo\")\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Surrounding first Group with z:\")\n",
    "print(gsub(\"(a+)\",\n",
    "           \"z\\\\1z\",\n",
    "           text,\n",
    "           perl = TRUE))\n",
    "print(\"Surrounding first Group with z and making it uppercase:\")\n",
    "print(gsub(\"(a+)\",\n",
    "           \"z\\\\U\\\\1z\",\n",
    "           text,\n",
    "           perl = TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]  TRUE  TRUE FALSE FALSE\n",
       "[1]  TRUE  TRUE FALSE FALSE\n",
       "  animal  likes appearence\n",
       "1    dog   meat      furry\n",
       "2    cat   meat      furry\n",
       "3  mouse cheese      furry\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "library(stringr)\n",
    "\n",
    "print(str_detect(c(\"Hult\", \"students\", \"love\", \"RegEx\"), \"u\"))\n",
    "print(grepl(\"u\", c(\"Hult\", \"students\", \"love\", \"RegEx\")))\n",
    "\n",
    "exampleDF = data.frame(animal = c(\"dog\", \"cat\", \"mouse\", \"fish\", \"chicken\"),\n",
    "                       likes = c(\"meat\", \"meat\", \"cheese\", \"who knows\", \"worm\"),\n",
    "                       appearence = c(\"furry\", \"furry\", \"furry\", \"scaly\", \"feathery\"))\n",
    "\n",
    "print(exampleDF[str_detect(exampleDF$appearence, \"furry\"),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1]]\n",
       "[1] \"05\"   \"25\"   \"2019\" \"19\"   \"05\"   \"23\"  \n",
       "\n",
       "     [,1] [,2] [,3]   [,4]      \n",
       "[1,] \"05\" \"25\" \"2019\" \"19:05:23\"\n",
       "     [,1] [,2] [,3]   [,4] [,5] [,6] [,7] [,8]\n",
       "[1,] \"05\" \"25\" \"2019\" \"19\" \"05\" \"23\" \"\"   \"\"  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "library(stringr)\n",
    "\n",
    "datetime = \"05/25/2019 19:05:23\"\n",
    "\n",
    "print(str_split(datetime,\n",
    "                \"[/: ]\"))\n",
    "print(str_split(datetime,\n",
    "                \"[/: ]\",\n",
    "                n = 4,\n",
    "                simplify = TRUE))\n",
    "print(str_split_fixed(datetime,\n",
    "                      \"[/: ]\",\n",
    "                      n = 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     start end\n",
       "[1,]    NA  NA\n",
       "[2,]     1   5\n",
       "[3,]     1   6\n",
       "[4,]    NA  NA\n",
       "[5,]     1   5\n",
       "[1] \"str_locate_all:\"\n",
       "[[1]]\n",
       "     start end\n",
       "[1,]     7   7\n",
       "[2,]     8   8\n",
       "\n",
       "[[2]]\n",
       "     start end\n",
       "[1,]     5   5\n",
       "\n",
       "[[3]]\n",
       "     start end\n",
       "[1,]     2   2\n",
       "[2,]     6   6\n",
       "[3,]     7   7\n",
       "[4,]     8   8\n",
       "\n",
       "[[4]]\n",
       "     start end\n",
       "[1,]     4   4\n",
       "\n",
       "[[5]]\n",
       "     start end\n",
       "[1,]     5   5\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "library(stringr)\n",
    "\n",
    "teststring = c(\"Powerful\", \"penguins\", \"playfully\", \"proliferate\", \"postures\")\n",
    "\n",
    "print(str_locate(teststring,\n",
    "                 \"p\\\\w+u\"))\n",
    "print(\"str_locate_all:\")\n",
    "print(str_locate_all(teststring,\n",
    "                     \"[lu]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"05\"\n",
       "[[1]]\n",
       "[1] \"05\"   \"25\"   \"2019\" \"19\"   \"05\"   \"23\"  \n",
       "\n",
       "     [,1] [,2] [,3]   [,4] [,5] [,6]\n",
       "[1,] \"05\" \"25\" \"2019\" \"19\" \"05\" \"23\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "library(stringr)\n",
    "\n",
    "datetime = \"05/25/2019 19:05:23\"\n",
    "\n",
    "print(str_extract(datetime,\n",
    "                  \"[^/: ]+\"))\n",
    "print(str_extract_all(datetime,\n",
    "                      \"[^/: ]+\"))\n",
    "print(str_extract_all(datetime,\n",
    "                      \"[^/: ]+\",\n",
    "                      simplify = TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"05/25/2019\"\n",
       "     [,1]         [,2] [,3] [,4]  \n",
       "[1,] \"05/25/2019\" \"05\" \"25\" \"2019\"\n",
       "[[1]]\n",
       "     [,1]         [,2] [,3] [,4]  \n",
       "[1,] \"05/25/2019\" \"05\" \"25\" \"2019\"\n",
       "[2,] \"19:05:23\"   \"19\" \"05\" \"23\"  \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "library(stringr)\n",
    "\n",
    "datetime = \"05/25/2019 19:05:23\"\n",
    "\n",
    "print(str_extract(datetime,\n",
    "                  \"(\\\\d+)[/: ](\\\\d+)[/: ](\\\\d+)\"))\n",
    "print(str_match(datetime,\n",
    "                \"(\\\\d+)[/: ](\\\\d+)[/: ](\\\\d+)\"))\n",
    "print(str_match_all(datetime,\n",
    "                    \"(\\\\d+)[/: ](\\\\d+)[/: ](\\\\d+)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"05:25/2019 19:05:23\"\n",
       "[1] \"05:25:2019 19:05:23\"\n",
       "[1] \"25/05/2019\" \"05/19:23\"  \n",
       "[1] \"25/05/2019\" \"xx:xx:23\"  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "library(stringr)\n",
    "\n",
    "datetime = \"05/25/2019 19:05:23\"\n",
    "\n",
    "print(str_replace(datetime,\n",
    "                  \"/\",\n",
    "                  \":\"))\n",
    "print(str_replace_all(datetime,\n",
    "                      \"/\",\n",
    "                      \":\"))\n",
    "datetime2 = c(\"05/25/2019\", \"19:05:23\")\n",
    "print(str_replace(datetime2,\n",
    "                  \"(\\\\d{1,2})[/:](\\\\d{1,2})\",\n",
    "                  \"\\\\2/\\\\1\"))\n",
    "print(str_replace_all(datetime2,\n",
    "                      \"(\\\\d{1,2})[/:](\\\\d{1,2})\",\n",
    "                      c(\"\\\\2/\\\\1\", \"xx:xx\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[90m# A tibble: 4 x 2\u001b[39m\n",
       "  .text  .match    \n",
       "\u001b[90m*\u001b[39m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<list>\u001b[39m\u001b[23m    \n",
       "\u001b[90m1\u001b[39m abc    \u001b[90m<list [3]>\u001b[39m\n",
       "\u001b[90m2\u001b[39m def    \u001b[90m<list [3]>\u001b[39m\n",
       "\u001b[90m3\u001b[39m cba a  \u001b[90m<list [3]>\u001b[39m\n",
       "\u001b[90m4\u001b[39m aa aaa \u001b[90m<list [3]>\u001b[39m\n",
       "\u001b[90m# A tibble: 4 x 2\u001b[39m\n",
       "  .text  .match    \n",
       "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<list>\u001b[39m\u001b[23m    \n",
       "\u001b[90m1\u001b[39m abc    \u001b[90m<list [3]>\u001b[39m\n",
       "\u001b[90m2\u001b[39m def    \u001b[90m<list [3]>\u001b[39m\n",
       "\u001b[90m3\u001b[39m cba a  \u001b[90m<list [3]>\u001b[39m\n",
       "\u001b[90m4\u001b[39m aa aaa \u001b[90m<list [3]>\u001b[39m\n",
       "[[1]]\n",
       "[[1]]$match\n",
       "[1] \"a\"\n",
       "\n",
       "[[1]]$start\n",
       "[1] 1\n",
       "\n",
       "[[1]]$end\n",
       "[1] 1\n",
       "\n",
       "\n",
       "[[2]]\n",
       "[[2]]$match\n",
       "[1] NA\n",
       "\n",
       "[[2]]$start\n",
       "[1] NA\n",
       "\n",
       "[[2]]$end\n",
       "[1] NA\n",
       "\n",
       "\n",
       "[[3]]\n",
       "[[3]]$match\n",
       "[1] \"a\"\n",
       "\n",
       "[[3]]$start\n",
       "[1] 3\n",
       "\n",
       "[[3]]$end\n",
       "[1] 3\n",
       "\n",
       "\n",
       "[[4]]\n",
       "[[4]]$match\n",
       "[1] \"aa\"\n",
       "\n",
       "[[4]]$start\n",
       "[1] 1\n",
       "\n",
       "[[4]]$end\n",
       "[1] 2\n",
       "\n",
       "\n",
       "attr(,\"class\")\n",
       "[1] \"rematch_records\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "library(rematch2)\n",
    "\n",
    "print(re_exec(c(\"abc\", \"def\", \"cba a\", \"aa aaa\"), \"a+\"))\n",
    "\n",
    "print(re_exec_all(c(\"abc\", \"def\", \"cba a\", \"aa aaa\"), \"a+\"))\n",
    "\n",
    "print(re_exec(c(\"abc\", \"def\", \"cba a\", \"aa aaa\"), \"a+\")$.match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[90m# A tibble: 4 x 2\u001b[39m\n",
       "  .text  .match\n",
       "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \n",
       "\u001b[90m1\u001b[39m abc    a     \n",
       "\u001b[90m2\u001b[39m def    \u001b[31mNA\u001b[39m    \n",
       "\u001b[90m3\u001b[39m cba a  a     \n",
       "\u001b[90m4\u001b[39m aa aaa aa    \n",
       "\u001b[90m# A tibble: 4 x 2\u001b[39m\n",
       "  .text  .match   \n",
       "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<list>\u001b[39m\u001b[23m   \n",
       "\u001b[90m1\u001b[39m abc    \u001b[90m<chr [1]>\u001b[39m\n",
       "\u001b[90m2\u001b[39m def    \u001b[90m<chr [0]>\u001b[39m\n",
       "\u001b[90m3\u001b[39m cba a  \u001b[90m<chr [2]>\u001b[39m\n",
       "\u001b[90m4\u001b[39m aa aaa \u001b[90m<chr [2]>\u001b[39m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "library(rematch2)\n",
    "\n",
    "print(re_match(c(\"abc\", \"def\", \"cba a\", \"aa aaa\"), \"a+\"))\n",
    "\n",
    "print(re_match_all(c(\"abc\", \"def\", \"cba a\", \"aa aaa\"), \"a+\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden"
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Regular Expression that:\n",
    "- Finds all 8 and 9 letter words that\n",
    "- contain the word \"dog\"\n",
    "- is optimized as much as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test String"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My antidogmatic bulldog likes to eat his hotdogs for their endogenous properties even though he doggishly admits to being boondoggled by dogmatic watchdogs that draw ondograms even in the dogwatches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Hint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "Use Positive Lookahead to match the length of the word followed by an expression that matches words containing \"dog\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Sample Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "Matching a 8-9 letter word is done by using the following:\n",
    "~~~\n",
    "\\b\\w{8,9}\\b\n",
    "~~~\n",
    "where `\\b` anchors the Expression at the word boundaries and `\\w{8,9}` means that between the word boundaries we need 8 or 9 characters.\n",
    "\n",
    "Matching a word that contains \"dog\" can be done by the following:\n",
    "~~~\n",
    "\\b\\w*dog\\w*\\b\n",
    "~~~\n",
    "Zero or more characters (`\\w*`) followed by \"dog\" followed by zero or more characters, all of this between word boundaries (`\\b`).\n",
    "\n",
    "To put the two together you can use [Positive Lookahead](#Positive-Lookahead). In the Lookahead group search for 8 and 9 letter words. As the Lookahead is not consuming characters the Regular Expression will still be at the beginning of the word that matches the Lookahead. This means you can than test for the word containing \"dog\".\n",
    "\n",
    "~~~\n",
    "(?=\\b\\w{8,9}\\b)\\b\\w*dog\\w*\\b\n",
    "~~~\n",
    "\n",
    "This expression works, but can be optimized:\n",
    "- the 3rd and 4th `\\b` are guarantied to match as the Lookahead already constrains the match between word boundaries and being anchors they don't add to the match result. Therefor they can be omitted.\n",
    "- The first `\\w*` can be made more specific. As the overall word length can not be longer than 9 characters and the word \"dog\" is 3 characters long there can be between 0 and 6 characters before the \"dog\". Replace `\\w*` with `\\w{0,6}`.\n",
    "- The first word boundary `\\b` can be placed outside of the Lookahead.\n",
    "\n",
    "**Final Expression:**\n",
    "\n",
    "~~~\n",
    "\\b(?=\\w{8,9}\\b)\\w{0,6}dog\\w*\n",
    "~~~\n",
    "\n",
    "[Flags](#Modes): `gmi`\n",
    "\n",
    "Found words:\n",
    "- doggishly\n",
    "- dogmatic\n",
    "- watchdogs\n",
    "- ondograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "[Solution in regex101](https://regex101.com/r/egYr7r/1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = font-size:0.85em;>Go to [Table of Contents](#TOC).</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "297.6000061035156px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
